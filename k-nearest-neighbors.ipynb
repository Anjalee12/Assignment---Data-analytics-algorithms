{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors (kNN)\n",
    "This Jupyter notebook summarizes the <a href=#pros>Pros</a> and <a href=#cons>Cons</a> of the k-Nearest Neighbors algorithm and gives two Python examples on usage for <a href=#clas>Classification</a> and <a href=#reg>Regression</a>. \n",
    "\n",
    "## Theory<sup>1,2,3</sup>  \n",
    "* Is a non-probabilistic, non-parametric and instance-based learning algorithm (see <a href=#reference>References</a>:\n",
    "    * **Non-parametric** means it makes no explicit assumptions about the function form of _h_, avoiding the dangers of mis-modelling the underlying distribution of the data\n",
    "        * For example, suppose our data is highly non-Gaussian but the learning model was choose assumes a Gaussian form. In that case, a parametric algorithm would make extremely poor predictions.\n",
    "    * **Instance-based** learning means that the algorithm does not explicitly learn a model\n",
    "        * Instead, it chooses to memorize the training instances which are subsequently used as \"knowledge\" for the prediction phase\n",
    "        * Concretely, this means that only when a query to our database is made (i.e., when we ask it to predict a label given an input), will the algorithm use the training instances to predict the result\n",
    "\n",
    "### Pros<a name=\"pros\"/> \n",
    "* **simple** to understand and implement\n",
    "* with **little to zero training time**\n",
    "* kNN **works just as easily with multi-class data** sets whereas other algorithms are hard-coded for the binary setting\n",
    "* the non-parametric nature of kNN gives it an edge in certain settings where the data may be highly unusual, thus **without prior knowledge on distribution**\n",
    "\n",
    "### Cons<a name=\"cons\"/> \n",
    "* **computationally expensive** testing phase\n",
    "    * we **need to store the whole data set for each decision**!\n",
    "* can **suffer from skewed class distributions**\n",
    "    * for example, if a certain class is very frequent in the training set, it will tend to dominate the majority voting of the new example (large number = more common)\n",
    "* the accuracy can be severally **degraded with high-dimension data** because of the little difference between the nearest and farthest neighbor\n",
    "    * **the curse of dimensionality** refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience\n",
    "    * for high-dimensional data (e.g., with number of dimensions more than 10) **scaling** and **dimension reductions** (such as PCA) is usually performed prior applying kNN\n",
    "    \n",
    "### References<a name=\"reference\"/>  \n",
    "* <sup>1</sup>Wikipedia [kNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm), [Curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality) \n",
    "* <sup>2</sup>Sklearn [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
    "* <sup>3</sup>[Complete Guide to K-Nearest-Neighbors](https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification<a name=\"clas\"/> \n",
    "* the output is a class membership\n",
    "* an object is classified by a **majority vote** of its neighbours, with the object being assigned to the class most common among its k nearest neighbours\n",
    "    * if k = 1, then the object is simply assigned to the class of that nearest neighbour\n",
    "    \n",
    "    \n",
    "### Example: predict [IRIS](https://scikit-learn.org/stable/datasets/index.html#iris-dataset) class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV , cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error,r2_score, mean_absolute_error,accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.datasets import load_wine\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vector drawing inside jupyter notebook\n",
    "%config InlineBackend.figure_format = \"svg\"\n",
    "\n",
    "# Set matplotlib default axis font size (inside this notebook)\n",
    "plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df = df.assign(target=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class distribution in target variable\n",
    "print(\"Class distribution:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data summary: extend the `describe` method by selected stats\n",
    "* See the Jupyter notebook on **Standard Procedure** for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute selected stats\n",
    "dfinfo = pd.DataFrame(df.dtypes,columns=[\"dtypes\"])\n",
    "for (m,n) in zip([df.count(),df.isna().sum()],[\"count\",\"isna\"]):\n",
    "    dfinfo = dfinfo.merge(pd.DataFrame(m,columns=[n]),right_index=True,left_index=True,how=\"inner\");\n",
    "\n",
    "\n",
    "# dfinfo.T.append(df.describe())\n",
    "\n",
    "dfinfo = pd.concat([dfinfo.T, df.describe()])\n",
    "dfinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show histogram (distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,2))\n",
    "for (i,v) in enumerate(df.columns):\n",
    "    plt.subplot(1,df.shape[1],i+1);\n",
    "    plt.hist(df.iloc[:,i],bins=\"sqrt\")\n",
    "    plt.title(df.columns[i],fontsize=9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "df_melted = df.melt(id_vars=\"target\", var_name=\"Features\", value_name=\"Value\")\n",
    "sns.boxplot(x=\"Features\", y=\"Value\", hue=\"target\", data=df_melted)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Feature Distributions by Target Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().round(2).style.background_gradient(cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale and try to **reduce dimensions**: what we try to do is to **always simply the model** if possible (see correlation matrix above)\n",
    "* More complex model (e.g., more features, or higher _*k*_) will (in theory) increase the probability of higher \"out of sample\" error (even when \"in sample\" error = train set) will be smaller!\n",
    "* Use either 99% threshold (own subjective) or \"mle\" algorithm (more objective)\n",
    "* Use **linear** scaler (transformation)\n",
    "* Here, the data is scaled prior train-test split. \n",
    "    * In real applications, first split and scale afterwards, to simulate real-world scenario where we do not have the test set! (otherwise data snooping effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scale = StandardScaler(with_mean=True,with_std=True);\n",
    "Xo = scale.fit_transform(df.drop([\"target\"],axis=1).values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xo = scaler.fit_transform(df.drop(columns=[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99)# or set n_components=\"mle\"\n",
    "X = pca.fit_transform(Xo)\n",
    "print(\"Nr. of features after PCA = {} (input = {})\".format(X.shape[1],Xo.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode target values (is not necessary for IRIS but still:-)\n",
    "y = LabelEncoder().fit_transform(df[\"target\"].values);\n",
    "\n",
    "# Split 2/3 to 1/3 train to test respectively\n",
    "[X_train,X_test,y_train,y_test] = train_test_split(X,y,train_size = 0.67,test_size = 0.33, stratify=y,random_state=123);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find optimal model\n",
    "* Considering the small data set (150 samples), find \"optimal\" k setting it to maximum of 5\n",
    "    * Optimal in terms of accuracy\n",
    "    * Simple model = higher probability of lower in and out-of sample error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(algorithm=\"auto\");\n",
    "parameters = {\"n_neighbors\":[1,3,5],\n",
    "              \"weights\":[\"uniform\",\"distance\"]}\n",
    "model_optim = GridSearchCV(model, parameters, cv=5,scoring=\"accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the \"optimal\" settings for kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,x,y) in zip([\"Train\",\"Test\"],[X_train,X_test],[y_train,y_test]):\n",
    "    print(\"Classification kNN\",i,\" report:\\n\",classification_report(y,model_optim.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"most_frequent\",\"uniform\"]:\n",
    "    dummy = DummyClassifier(strategy=i).fit(X_train,y_train);\n",
    "    print(\"Classification \",i,\" test report:\",classification_report(y_test,dummy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different values of k\n",
    "k_values = range(1, 21)\n",
    "error_rates = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy') \n",
    "    error_rates.append(1 - scores.mean())  # Convert accuracy to error rate\n",
    "\n",
    "# Plot the Elbow Method\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(k_values, error_rates, marker='o', linestyle='dashed', color='b')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best k from the elbow point\n",
    "optimal_k = k_values[np.argmin(error_rates)]\n",
    "print(f\"Optimal k found: {optimal_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show resulting accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the precision (accuracy=macro avg precision) is very high. \n",
    "Just to show that that is not coincidence compare to \"dummy\" model (most frequent & uniform distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression<a name=\"reg\"/> \n",
    "* Predicts value as the **average of the values** of its k nearest neighbors\n",
    "\n",
    "### Example: Predict House price\n",
    "* Use Scikit-learn [California Housing](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset) data set\n",
    "    * This is a large data set that allows us to use more complex model\n",
    "* Nontheless, try to reduce the number of features: via visual inspection and using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"../input/test-data/california_housing.csv\").drop(columns=[\"Unnamed: 0\"],errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = datasets.fetch_california_housing()\n",
    "df = pd.DataFrame(house.data,columns=house.feature_names)\n",
    "df = df.assign(target=house.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect data: show statistics, histogram and correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute selected stats\n",
    "dfinfo = pd.DataFrame(df.dtypes,columns=[\"dtypes\"])\n",
    "for (m,n) in zip([df.count(),df.isna().sum()],[\"count\",\"isna\"]):\n",
    "    dfinfo = dfinfo.merge(pd.DataFrame(m,columns=[n]),right_index=True,left_index=True,how=\"inner\");\n",
    "\n",
    "#dfinfo.T.append(df.describe())\n",
    "dfinfo = pd.concat([dfinfo.T, df.describe()])\n",
    "dfinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "for (i,v) in enumerate(df.columns):\n",
    "    plt.subplot(2,5,i+1);\n",
    "    plt.hist(df.iloc[:,i],50,density=True)\n",
    "    plt.legend([df.columns[i]],fontsize=6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().round(2).style.background_gradient(cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for fitting by scaling data set\n",
    "* Here, the data is scaled prior train-test split. \n",
    "    * In real applications, first split and scale afterwards, to simulate real-world scenario where we do not have the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(df.drop(\"target\",axis=1).values);\n",
    "y = df.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Reduction\n",
    "* Considering the correlation, histogram and the summary table:\n",
    "    * Remove/drop \"AveOccup\" (average house occupancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop([\"AveOccup\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"target\"])  \n",
    "y = df[\"target\"]\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=5)  # Select top 5 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = PCA(n_components=\"mle\").fit_transform(X)\n",
    "print(\"Nr. of features after reduction = {} (input = {})\".format(X.shape[1],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA considering selected features\n",
    "\n",
    "selected_feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Latitude']\n",
    "X_selected = df[selected_feature_names]\n",
    "\n",
    "pca = PCA(n_components=\"mle\")  \n",
    "X = pca.fit_transform(X_selected)\n",
    "\n",
    "#Print the number of features after PCA\n",
    "print(f\"Number of features after PCA: {X.shape[1]} (input = {X_selected.shape[1]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test] = train_test_split(X,y,train_size=0.67,test_size=0.33,random_state=123);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor();\n",
    "\n",
    "parameters = {\"n_neighbors\":[1,3,5,7,9],\"weights\":[\"uniform\",\"distance\"]}\n",
    "\n",
    "knn_reg = GridSearchCV(knn, parameters, cv=5, scoring=\"neg_mean_squared_error\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(knn_reg.predict(X_test),y_test))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2_score(knn_reg.predict(X_test),y_test):.4f}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(knn_reg.predict(X_test),y_test):.4f}\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(knn_reg.predict(X_test),y_test):.4f}\")\n",
    "\n",
    "print(\"Regression kNN (test) RMSE \\t= {:.0f} *1000$\".format(\n",
    "    100*np.sqrt(mean_squared_error(knn_reg.predict(X_test),y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 5, 1)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1, 2] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=\"r2\")  \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "print(\"Best K:\", grid_search.best_params_[\"n_neighbors\"])\n",
    "print(\"Best Weights:\", grid_search.best_params_[\"weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_list = []\n",
    "k_values = list(range(1, 10, 2)) \n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights=\"distance\")\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Compute RMSE \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  \n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, rmse_list, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
    "plt.xlabel(\"k (Neighbors)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Elbow Method for Optimal k\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Changed.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of kNN - Wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wine dataset\n",
    "\n",
    "data = load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split, train and predict k-NN model\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a basic k-NN \n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Initial Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'n_neighbors': range(1, 31), 'weights': ['uniform', 'distance']}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_weights = grid_search.best_params_['weights']\n",
    "print(f\"Best k: {best_k}, Best weights: {best_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the optimized model\n",
    "knn_optimized = KNeighborsClassifier(n_neighbors=best_k, weights=best_weights)\n",
    "knn_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with optimized model\n",
    "y_pred_optimized = knn_optimized.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Evaluation of optimized model\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"Optimized Model Accuracy: {accuracy_optimized:.4f}\")\n",
    "print(\"Classification Report (Optimized Model):\\n\", classification_report(y_test, y_pred_optimized))\n",
    "print(\"Confusion Matrix (Optimized Model):\\n\", confusion_matrix(y_test, y_pred_optimized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(knn_optimized, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation mean accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Compare performance\n",
    "print(f\"Accuracy Improvement: {accuracy_optimized - accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Regression KNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Diabetes dataset\n",
    "data = load_diabetes()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target variable\n",
    "\n",
    "# Split dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (Default)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default KNN Model (k=5, Euclidean)\n",
    "knn_default = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_default.fit(X_train_scaled, y_train)\n",
    "y_pred_default = knn_default.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_default)\n",
    "mse = mean_squared_error(y_test, y_pred_default)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_default)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with Manhattan Distance\n",
    "knn_manhattan = KNeighborsRegressor(n_neighbors=5, metric='manhattan')\n",
    "knn_manhattan.fit(X_train_scaled, y_train)\n",
    "y_pred_manhattan = knn_manhattan.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred_manhattan)\n",
    "mse = mean_squared_error(y_test, y_pred_manhattan)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_manhattan)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
    "X_test_minmax = scaler_minmax.transform(X_test)\n",
    "knn_minmax = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_minmax.fit(X_train_minmax, y_train)\n",
    "y_pred_minmax = knn_minmax.predict(X_test_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred_minmax)\n",
    "mse = mean_squared_error(y_test, y_pred_minmax)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_minmax)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Default KNN\", \"Manhattan\", \"MinMax Scaling\"]\n",
    "predictions = [y_pred_default, y_pred_manhattan, y_pred_minmax]\n",
    "\n",
    "results = []\n",
    "for model, y_pred in zip(models, predictions):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results.append([model, mae, mse, rmse, r2])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"MAE\", \"MSE\", \"RMSE\", \"R² Score\"])\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df.sort_values(by=\"R² Score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
